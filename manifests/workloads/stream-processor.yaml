apiVersion: apps/v1
kind: Deployment
metadata:
  name: stream-processor
  labels:
    app: stream-processor
  annotations:
    slo.hybrid.io/class: "latency"
    slo.hybrid.io/latencyTargetMs: "50"
    # slo.hybrid.io/max-offload-penalty.ms: "15"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stream-processor
  template:
    metadata:
      labels:
        app: stream-processor
        scheduling.hybrid.io/managed: "true"
    spec:
      containers:
        - name: processor
          image: python:3.11-slim
          ports:
            - containerPort: 8080
          command:
            - bash
            - -lc
            - |
              set -euo pipefail
              pip install --no-cache-dir flask numpy
              python - <<'PY'
              from flask import Flask, request, jsonify
              import numpy as np, time, math, threading
              from collections import deque
              app = Flask(__name__)
              data_window = deque(maxlen=1000)
              lock = threading.Lock()
              def sf(v): 
                  try:
                      f = float(v)
                      return 0.0 if (math.isnan(f) or math.isinf(f)) else f
                  except: return 0.0
              @app.get("/health")
              def health(): return jsonify({"status":"healthy","window_size":len(data_window)})
              @app.post("/process")
              def process():
                  t0 = time.time()
                  try:
                      d = request.get_json(force=True)
                      vals = [sf(x) for x in d.get("values",[])]
                      if not vals: return jsonify({"error":"no values"}), 400
                      arr = np.array(vals, dtype=float)
                      m = float(np.mean(arr)); s = float(np.std(arr))
                      with lock:
                          data_window.append({"mean":m,"t":time.time()})
                          recent = list(data_window)[-10:]
                          if recent:
                              rmean = float(np.mean([x["mean"] for x in recent]))
                              rstd  = float(np.std([x["mean"] for x in recent]))
                          else:
                              rmean, rstd = m, 0.0
                      pt = (time.time()-t0)*1000
                      anomaly = abs(m-rmean) > 2*rstd if rstd>0 else False
                      return jsonify(dict(processed_value=sf(m),
                                          rolling_average=sf(rmean),
                                          anomaly_detected=bool(anomaly),
                                          processing_time_ms=sf(pt),
                                          window_size=len(data_window)))
                  except Exception as e:
                      return jsonify({"error":str(e)}), 400
              @app.get("/stats")
              def stats(): return jsonify({"total_processed":len(data_window),"window_size":len(data_window)})
              if __name__ == "__main__": app.run(host="0.0.0.0", port=8080, threaded=True)
              PY
          readinessProbe:
            httpGet: { path: /health, port: 8080 }
            initialDelaySeconds: 5
            periodSeconds: 3
            timeoutSeconds: 2
          livenessProbe:
            httpGet: { path: /health, port: 8080 }
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 3
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
---
apiVersion: v1
kind: Service
metadata:
  name: stream-processor
  labels:
    app: stream-processor
spec:
  selector:
    app: stream-processor
  ports:
    - name: http
      port: 8080
      targetPort: 8080
      protocol: TCP
  type: ClusterIP
---
apiVersion: batch/v1
kind: Job
metadata:
  name: stream-data-generator
  labels:
    app: stream-data-generator
  annotations:
    slo.hybrid.io/class: "latency"
    slo.hybrid.io/latencyTargetMs: "100"
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: stream-data-generator
        scheduling.hybrid.io/managed: "true"
    spec:
      restartPolicy: Never
      containers:
        - name: generator
          image: python:3.11-slim
          env:
            - name: PROCESSOR_URL
              value: "http://stream-processor:8080"
            - name: TEST_SEC
              value: "120"
            - name: RATE_HZ
              value: "20"
          command:
            - bash
            - -c
            - |
              set -euo pipefail
              pip install --no-cache-dir requests numpy
              python - <<'PY'
              import requests, numpy as np, time, os, random, math, json
              U=os.getenv("PROCESSOR_URL")
              TEST_SEC=int(os.getenv("TEST_SEC","120"))
              RATE=float(os.getenv("RATE_HZ","10"))
              def sf(v):
                  try:
                      f=float(v)
                      return 0.0 if (math.isnan(f) or math.isinf(f)) else f
                  except: return 0.0
              print("Wait for processor...")
              for _ in range(30):
                  try:
                      if requests.get(f"{U}/health",timeout=2).status_code==200: break
                  except: pass
                  time.sleep(2)
              total=lat=anom=err=0
              end=time.time()+TEST_SEC
              period=1.0/max(RATE,1.0)
              while time.time()<end:
                  v = np.random.normal(50,5,20) if random.random()>0.05 else np.random.normal(100,50,20)
                  data={"timestamp":time.time(),"sensor_id":"s","values":[sf(x) for x in v.tolist()]}
                  t0=time.time()
                  try:
                      r=requests.post(f"{U}/process",json=data,timeout=1.0)
                      l=(time.time()-t0)*1000
                      if r.status_code==200:
                          j=r.json()
                          if j.get("anomaly_detected"): anom+=1
                          total+=1; lat+=l
                      else: err+=1
                  except requests.exceptions.Timeout: err+=1
                  except Exception: err+=1
                  sl=period-(time.time()-t0); 
                  if sl>0: time.sleep(sl)
              print("=== STREAM RESULTS ===")
              print("Total successful:",total)
              print("Total errors:",err)
              if total>0:
                print("Average latency:",round(lat/total,2),"ms")
                print("Anomalies detected:",anom)
              try:
                s=requests.get(f"{U}/stats",timeout=3)
                if s.ok: print("Processor stats:",s.json())
              except: pass
              PY
          resources:
            requests: { cpu: "200m", memory: "128Mi" }
            limits:   { cpu: "400m", memory: "256Mi" }